{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Оределяем последовательности x и y**"
      ],
      "metadata": {
        "id": "oZtQttQlHxf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoO87kxq0tXz"
      },
      "outputs": [],
      "source": [
        "import random as r\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "import re\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **25,70,120**"
      ],
      "metadata": {
        "id": "d6hP4mjPm2oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1,x2,x3 = [],[],[]"
      ],
      "metadata": {
        "id": "EyFcauvcheJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(25):\n",
        "  x1.append(r.randint(0,9))\n",
        "for i in range(70):\n",
        "  x2.append(r.randint(0,9))\n",
        "for i in range(120):\n",
        "  x3.append(r.randint(0,9))"
      ],
      "metadata": {
        "id": "KaJOczwo1Glq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x1),len(x2),len(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY_xXEAKmkML",
        "outputId": "944c4447-02e1-426a-b99c-09a4a36dd782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 70, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1),print(x2),print(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lePWK1CMmu4L",
        "outputId": "c173bca1-771b-450a-866d-a84aefd5e7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 9, 6, 3, 4, 8, 8, 9, 6, 1, 1, 1, 1, 8, 0, 5, 0, 7, 6, 1, 0, 2, 2]\n",
            "[1, 9, 3, 8, 6, 4, 3, 2, 1, 5, 0, 8, 1, 3, 6, 0, 4, 1, 6, 4, 4, 1, 5, 9, 3, 2, 6, 1, 3, 7, 1, 2, 3, 1, 9, 7, 8, 1, 4, 5, 6, 9, 9, 0, 6, 2, 9, 3, 2, 7, 6, 6, 9, 4, 8, 5, 0, 8, 0, 0, 7, 9, 5, 2, 3, 6, 2, 4, 0, 1]\n",
            "[5, 7, 3, 4, 3, 7, 7, 7, 2, 2, 7, 6, 1, 4, 0, 4, 9, 8, 3, 2, 4, 0, 2, 8, 6, 4, 7, 6, 8, 5, 7, 0, 1, 5, 7, 6, 4, 7, 4, 2, 1, 4, 3, 6, 3, 2, 9, 7, 9, 5, 8, 5, 0, 7, 5, 4, 7, 1, 8, 0, 3, 8, 8, 5, 6, 8, 9, 6, 5, 5, 8, 1, 1, 7, 8, 8, 4, 4, 4, 5, 9, 3, 5, 9, 6, 9, 8, 3, 1, 4, 5, 1, 6, 6, 3, 7, 8, 5, 5, 4, 9, 2, 7, 9, 4, 3, 0, 3, 4, 7, 9, 7, 8, 7, 4, 9, 6, 6, 9, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  if x>=10:\n",
        "    return x-10\n",
        "  else:\n",
        "    return x"
      ],
      "metadata": {
        "id": "1DCdJRyj6uJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1,y2,y3 = [x1[0]],[x2[0]],[x3[0]]\n",
        "y1,y2,y3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4yzqvhnLFX",
        "outputId": "ab78af10-435f-41d2-a1d9-71d735e75932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1], [1], [5])"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in x1[1:]:\n",
        "   y1.append(f(i+x1[0]))\n",
        "for i in x2[1:]:\n",
        "   y2.append(f(i+x2[0]))\n",
        "for i in x3[1:]:\n",
        "   y3.append(f(i+x3[0]))"
      ],
      "metadata": {
        "id": "uvokoHVh1GXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y1),print(y2),print(y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZEwOQCwnoWT",
        "outputId": "55366466-67f9-4a2c-9738-a1e983afbc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 3, 0, 7, 4, 5, 9, 9, 0, 7, 2, 2, 2, 2, 9, 1, 6, 1, 8, 7, 2, 1, 3, 3]\n",
            "[1, 0, 4, 9, 7, 5, 4, 3, 2, 6, 1, 9, 2, 4, 7, 1, 5, 2, 7, 5, 5, 2, 6, 0, 4, 3, 7, 2, 4, 8, 2, 3, 4, 2, 0, 8, 9, 2, 5, 6, 7, 0, 0, 1, 7, 3, 0, 4, 3, 8, 7, 7, 0, 5, 9, 6, 1, 9, 1, 1, 8, 0, 6, 3, 4, 7, 3, 5, 1, 2]\n",
            "[5, 2, 8, 9, 8, 2, 2, 2, 7, 7, 2, 1, 6, 9, 5, 9, 4, 3, 8, 7, 9, 5, 7, 3, 1, 9, 2, 1, 3, 0, 2, 5, 6, 0, 2, 1, 9, 2, 9, 7, 6, 9, 8, 1, 8, 7, 4, 2, 4, 0, 3, 0, 5, 2, 0, 9, 2, 6, 3, 5, 8, 3, 3, 0, 1, 3, 4, 1, 0, 0, 3, 6, 6, 2, 3, 3, 9, 9, 9, 0, 4, 8, 0, 4, 1, 4, 3, 8, 6, 9, 0, 6, 1, 1, 8, 2, 3, 0, 0, 9, 4, 7, 2, 4, 9, 8, 5, 8, 9, 2, 4, 2, 3, 2, 9, 4, 1, 1, 4, 8]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor([x1[i:i+5] for i in range (0,len(x1), 5)])\n",
        "x2 = torch.tensor([x2[i:i+5] for i in range (0,len(x2), 5)])\n",
        "x3 = torch.tensor([x3[i:i+5] for i in range (0,len(x3), 5)])\n",
        "y1 = torch.tensor([y1[i:i+5] for i in range (0,len(y1), 5)])\n",
        "y2 = torch.tensor([y2[i:i+5] for i in range (0,len(y2), 5)])\n",
        "y3 = torch.tensor([y3[i:i+5] for i in range (0,len(y3), 5)])"
      ],
      "metadata": {
        "id": "-75FJf9fbxyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXhP1VLQjg3G",
        "outputId": "1e98f262-3b88-49ad-920b-03dff98440cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 3, 3, 0, 7],\n",
            "        [4, 5, 9, 9, 0],\n",
            "        [7, 2, 2, 2, 2],\n",
            "        [9, 1, 6, 1, 8],\n",
            "        [7, 2, 1, 3, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Модель RNN**"
      ],
      "metadata": {
        "id": "XR_UldrGXt_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Смотрим на Embedding и RNN ячейку"
      ],
      "metadata": {
        "id": "a6jFPVwv-I6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHARS = [0,1,2,3,4,5,6,7,8,9]"
      ],
      "metadata": {
        "id": "J9-Rqa7FaRiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = torch.nn.Embedding(len(CHARS), 15)\n",
        "t = embeddings(x1)\n",
        "t[0]"
      ],
      "metadata": {
        "id": "dG4Brr_aJ2Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e8d9e1-337e-40cb-ac1a-4bf6238796fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6189,  0.3972, -0.6679,  0.3400, -0.6360, -0.7316, -1.1589, -0.1603,\n",
              "          0.0631, -1.0699,  1.2731,  0.6686,  1.0052, -0.0777,  0.6290],\n",
              "        [-0.4420, -0.5857,  0.1591, -0.7988, -0.7315, -0.0268, -0.4590, -1.4148,\n",
              "         -0.6451,  0.2866,  0.3733,  2.1469, -0.4025,  0.1449, -0.0315],\n",
              "        [-0.4420, -0.5857,  0.1591, -0.7988, -0.7315, -0.0268, -0.4590, -1.4148,\n",
              "         -0.6451,  0.2866,  0.3733,  2.1469, -0.4025,  0.1449, -0.0315],\n",
              "        [-0.1692,  1.2158,  0.1906,  0.6868,  0.9732,  0.9720, -1.6931,  0.1763,\n",
              "         -0.4464, -0.1685, -0.7349, -0.8662, -0.5857, -0.4399, -0.3887],\n",
              "        [-1.1006, -0.8602, -1.2551, -0.9803, -0.2220,  1.1316, -0.2123, -0.4866,\n",
              "         -0.5428, -1.3449, -0.7912, -0.2695,  0.8257, -2.7425,  0.8186]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm5CyAkV1Ijq",
        "outputId": "5bdd386c-0cd7-4491-9ff9-ba5869534cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(10, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = torch.nn.RNN(15, 128, batch_first=True)\n",
        "o, s = rnn(t)\n",
        "o.shape, s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhsR2yer9YLD",
        "outputId": "8f93cd6d-48df-4829-e807-0d47c98f7c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5, 128]), torch.Size([1, 5, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o, s2 = rnn(t, s)\n",
        "o.shape, s2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOLieysH9YHr",
        "outputId": "e5500fdf-9c16-487b-842c-eb325e5a13ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5, 128]), torch.Size([1, 5, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uAczUPYApXTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = nn.RNN(15, 128, batch_first=True)"
      ],
      "metadata": {
        "id": "85HCwzPSoITu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network_rnn(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network_rnn, self).__init__()\n",
        "        self.embed = torch.nn.Embedding(len(CHARS), 15)\n",
        "        self.rnn = torch.nn.RNN(15, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128,len(CHARS))\n",
        "    def forward(self, sentences, state=None):\n",
        "        embed = self.embed(sentences)\n",
        "        o,s = self.rnn(embed)\n",
        "        out = self.linear(o)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6xQ2y7e19YE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:20:53.260599Z",
          "start_time": "2020-03-12T15:20:53.256979Z"
        },
        "id": "-f4VNsqAuvsD"
      },
      "outputs": [],
      "source": [
        "model = Network_rnn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
      ],
      "metadata": {
        "id": "3UNFYWOPq_qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(x1,y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-emQvaskrtef",
        "outputId": "548a5b8c-f5a1-4434-d37c-1d6013bdc9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.011, Train loss: 2.330\n",
            "\rEpoch 1, loss 2.122\rEpoch 2, loss 1.937\rEpoch 3, loss 1.767\rEpoch 4, loss 1.614\n",
            "Epoch 5. Time: 0.005, Train loss: 1.479\n",
            "\rEpoch 6, loss 1.361\rEpoch 7, loss 1.255\rEpoch 8, loss 1.159\rEpoch 9, loss 1.071\n",
            "Epoch 10. Time: 0.006, Train loss: 0.990\n",
            "\rEpoch 11, loss 0.916\rEpoch 12, loss 0.849\rEpoch 13, loss 0.789\rEpoch 14, loss 0.734\n",
            "Epoch 15. Time: 0.006, Train loss: 0.686\n",
            "\rEpoch 16, loss 0.643\rEpoch 17, loss 0.606\rEpoch 18, loss 0.572\rEpoch 19, loss 0.542\n",
            "Epoch 20. Time: 0.006, Train loss: 0.516\n",
            "\rEpoch 21, loss 0.492\rEpoch 22, loss 0.471\rEpoch 23, loss 0.453\rEpoch 24, loss 0.436\n",
            "Epoch 25. Time: 0.006, Train loss: 0.420\n",
            "\rEpoch 26, loss 0.406\rEpoch 27, loss 0.393\rEpoch 28, loss 0.381\rEpoch 29, loss 0.370\n",
            "Epoch 30. Time: 0.006, Train loss: 0.360\n",
            "Epoch 34, loss 0.324\n",
            "Epoch 35. Time: 0.008, Train loss: 0.316\n",
            "Epoch 39, loss 0.288\n",
            "Epoch 40. Time: 0.006, Train loss: 0.282\n",
            "Epoch 44, loss 0.258\n",
            "Epoch 45. Time: 0.006, Train loss: 0.253\n",
            "Epoch 49, loss 0.233\n",
            "Epoch 50. Time: 0.007, Train loss: 0.229\n",
            "Epoch 54, loss 0.213\n",
            "Epoch 55. Time: 0.005, Train loss: 0.209\n",
            "Epoch 59, loss 0.196\n",
            "Epoch 60. Time: 0.005, Train loss: 0.193\n",
            "Epoch 64, loss 0.183\n",
            "Epoch 65. Time: 0.006, Train loss: 0.181\n",
            "Epoch 69, loss 0.172\n",
            "Epoch 70. Time: 0.008, Train loss: 0.170\n",
            "Epoch 74, loss 0.164\n",
            "Epoch 75. Time: 0.005, Train loss: 0.162\n",
            "Epoch 79, loss 0.156\n",
            "Epoch 80. Time: 0.006, Train loss: 0.155\n",
            "Epoch 84, loss 0.151\n",
            "Epoch 85. Time: 0.006, Train loss: 0.150\n",
            "Epoch 89, loss 0.146\n",
            "Epoch 90. Time: 0.006, Train loss: 0.145\n",
            "Epoch 94, loss 0.141\n",
            "Epoch 95. Time: 0.006, Train loss: 0.141\n",
            "Epoch 99, loss 0.138\n",
            "Epoch 100. Time: 0.005, Train loss: 0.137\n",
            "Epoch 104, loss 0.135\n",
            "Epoch 105. Time: 0.005, Train loss: 0.134\n",
            "Epoch 109, loss 0.132\n",
            "Epoch 110. Time: 0.006, Train loss: 0.131\n",
            "Epoch 114, loss 0.130\n",
            "Epoch 115. Time: 0.005, Train loss: 0.129\n",
            "Epoch 119, loss 0.127\n",
            "Epoch 120. Time: 0.005, Train loss: 0.127\n",
            "Epoch 124, loss 0.125\n",
            "Epoch 125. Time: 0.007, Train loss: 0.125\n",
            "Epoch 129, loss 0.124\n",
            "Epoch 130. Time: 0.006, Train loss: 0.123\n",
            "Epoch 134, loss 0.122\n",
            "Epoch 135. Time: 0.005, Train loss: 0.122\n",
            "Epoch 139, loss 0.120\n",
            "Epoch 140. Time: 0.005, Train loss: 0.120\n",
            "Epoch 144, loss 0.119\n",
            "Epoch 145. Time: 0.007, Train loss: 0.119\n",
            "Epoch 149, loss 0.118\n",
            "Epoch 150. Time: 0.005, Train loss: 0.118\n",
            "Epoch 154, loss 0.117\n",
            "Epoch 155. Time: 0.005, Train loss: 0.116\n",
            "Epoch 159, loss 0.116\n",
            "Epoch 160. Time: 0.005, Train loss: 0.115\n",
            "Epoch 164, loss 0.115\n",
            "Epoch 165. Time: 0.008, Train loss: 0.114\n",
            "Epoch 169, loss 0.114\n",
            "Epoch 170. Time: 0.006, Train loss: 0.113\n",
            "Epoch 174, loss 0.113\n",
            "Epoch 175. Time: 0.006, Train loss: 0.113\n",
            "Epoch 179, loss 0.112\n",
            "Epoch 180. Time: 0.006, Train loss: 0.112\n",
            "Epoch 184, loss 0.111\n",
            "Epoch 185. Time: 0.006, Train loss: 0.111\n",
            "Epoch 189, loss 0.110\n",
            "Epoch 190. Time: 0.005, Train loss: 0.110\n",
            "Epoch 194, loss 0.110\n",
            "Epoch 195. Time: 0.006, Train loss: 0.109\n",
            "Epoch 199, loss 0.109"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x2,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StLZqYgJriaX",
        "outputId": "dc9f1484-6323-4a50-f2eb-cb11642eaff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.026, Train loss: 5.384\n",
            "\rEpoch 1, loss 2.999\rEpoch 2, loss 2.156\rEpoch 3, loss 1.756\rEpoch 4, loss 1.513\n",
            "Epoch 5. Time: 0.014, Train loss: 1.335\n",
            "\rEpoch 6, loss 1.191\rEpoch 7, loss 1.069\rEpoch 8, loss 0.965\rEpoch 9, loss 0.877\n",
            "Epoch 10. Time: 0.014, Train loss: 0.801\n",
            "Epoch 14, loss 0.588\n",
            "Epoch 15. Time: 0.013, Train loss: 0.551\n",
            "Epoch 19, loss 0.443\n",
            "Epoch 20. Time: 0.015, Train loss: 0.424\n",
            "Epoch 24, loss 0.369\n",
            "Epoch 25. Time: 0.014, Train loss: 0.360\n",
            "Epoch 29, loss 0.332\n",
            "Epoch 30. Time: 0.016, Train loss: 0.327\n",
            "Epoch 34, loss 0.311\n",
            "Epoch 35. Time: 0.016, Train loss: 0.308\n",
            "Epoch 39, loss 0.299\n",
            "Epoch 40. Time: 0.014, Train loss: 0.297\n",
            "Epoch 44, loss 0.291\n",
            "Epoch 45. Time: 0.014, Train loss: 0.289\n",
            "Epoch 49, loss 0.285\n",
            "Epoch 50. Time: 0.014, Train loss: 0.284\n",
            "Epoch 54, loss 0.281\n",
            "Epoch 55. Time: 0.029, Train loss: 0.280\n",
            "Epoch 59, loss 0.277\n",
            "Epoch 60. Time: 0.014, Train loss: 0.276\n",
            "Epoch 64, loss 0.274\n",
            "Epoch 65. Time: 0.014, Train loss: 0.274\n",
            "Epoch 69, loss 0.272\n",
            "Epoch 70. Time: 0.017, Train loss: 0.271\n",
            "Epoch 74, loss 0.270\n",
            "Epoch 75. Time: 0.014, Train loss: 0.269\n",
            "Epoch 79, loss 0.268\n",
            "Epoch 80. Time: 0.014, Train loss: 0.268\n",
            "Epoch 84, loss 0.266\n",
            "Epoch 85. Time: 0.019, Train loss: 0.266\n",
            "Epoch 89, loss 0.265\n",
            "Epoch 90. Time: 0.016, Train loss: 0.264\n",
            "Epoch 94, loss 0.263\n",
            "Epoch 95. Time: 0.015, Train loss: 0.263\n",
            "Epoch 99, loss 0.262\n",
            "Epoch 100. Time: 0.014, Train loss: 0.262\n",
            "Epoch 104, loss 0.261\n",
            "Epoch 105. Time: 0.015, Train loss: 0.261\n",
            "Epoch 109, loss 0.260\n",
            "Epoch 110. Time: 0.014, Train loss: 0.260\n",
            "Epoch 114, loss 0.259\n",
            "Epoch 115. Time: 0.015, Train loss: 0.259\n",
            "Epoch 119, loss 0.258\n",
            "Epoch 120. Time: 0.016, Train loss: 0.258\n",
            "Epoch 124, loss 0.257\n",
            "Epoch 125. Time: 0.014, Train loss: 0.257\n",
            "Epoch 129, loss 0.256\n",
            "Epoch 130. Time: 0.017, Train loss: 0.256\n",
            "Epoch 134, loss 0.255\n",
            "Epoch 135. Time: 0.024, Train loss: 0.255\n",
            "Epoch 139, loss 0.254\n",
            "Epoch 140. Time: 0.016, Train loss: 0.254\n",
            "Epoch 144, loss 0.254\n",
            "Epoch 145. Time: 0.016, Train loss: 0.254\n",
            "Epoch 149, loss 0.253\n",
            "Epoch 150. Time: 0.018, Train loss: 0.253\n",
            "Epoch 154, loss 0.252\n",
            "Epoch 155. Time: 0.015, Train loss: 0.252\n",
            "Epoch 159, loss 0.252\n",
            "Epoch 160. Time: 0.016, Train loss: 0.251\n",
            "Epoch 164, loss 0.251\n",
            "Epoch 165. Time: 0.015, Train loss: 0.251\n",
            "Epoch 169, loss 0.250\n",
            "Epoch 170. Time: 0.014, Train loss: 0.250\n",
            "Epoch 174, loss 0.250\n",
            "Epoch 175. Time: 0.019, Train loss: 0.250\n",
            "Epoch 179, loss 0.249\n",
            "Epoch 180. Time: 0.015, Train loss: 0.249\n",
            "Epoch 184, loss 0.249\n",
            "Epoch 185. Time: 0.013, Train loss: 0.249\n",
            "Epoch 189, loss 0.248\n",
            "Epoch 190. Time: 0.014, Train loss: 0.248\n",
            "Epoch 194, loss 0.248\n",
            "Epoch 195. Time: 0.013, Train loss: 0.247\n",
            "Epoch 199, loss 0.247"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x3,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek-PE-ROruLj",
        "outputId": "234576ef-8707-4a38-bcec-743ff042d967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.033, Train loss: 5.543\n",
            "\rEpoch 1, loss 3.140\rEpoch 2, loss 2.198\rEpoch 3, loss 1.694\rEpoch 4, loss 1.395\n",
            "Epoch 5. Time: 0.024, Train loss: 1.200\n",
            "Epoch 9, loss 0.803\n",
            "Epoch 10. Time: 0.030, Train loss: 0.749\n",
            "Epoch 14, loss 0.610\n",
            "Epoch 15. Time: 0.023, Train loss: 0.588\n",
            "Epoch 19, loss 0.526\n",
            "Epoch 20. Time: 0.022, Train loss: 0.516\n",
            "Epoch 24, loss 0.485\n",
            "Epoch 25. Time: 0.023, Train loss: 0.479\n",
            "Epoch 29, loss 0.462\n",
            "Epoch 30. Time: 0.026, Train loss: 0.459\n",
            "Epoch 34, loss 0.448\n",
            "Epoch 35. Time: 0.029, Train loss: 0.446\n",
            "Epoch 39, loss 0.439\n",
            "Epoch 40. Time: 0.035, Train loss: 0.437\n",
            "Epoch 44, loss 0.432\n",
            "Epoch 45. Time: 0.029, Train loss: 0.431\n",
            "Epoch 49, loss 0.427\n",
            "Epoch 50. Time: 0.030, Train loss: 0.427\n",
            "Epoch 54, loss 0.423\n",
            "Epoch 55. Time: 0.034, Train loss: 0.423\n",
            "Epoch 59, loss 0.420\n",
            "Epoch 60. Time: 0.033, Train loss: 0.420\n",
            "Epoch 64, loss 0.418\n",
            "Epoch 65. Time: 0.032, Train loss: 0.417\n",
            "Epoch 69, loss 0.415\n",
            "Epoch 70. Time: 0.029, Train loss: 0.415\n",
            "Epoch 74, loss 0.413\n",
            "Epoch 75. Time: 0.029, Train loss: 0.413\n",
            "Epoch 79, loss 0.411\n",
            "Epoch 80. Time: 0.034, Train loss: 0.411\n",
            "Epoch 84, loss 0.410\n",
            "Epoch 85. Time: 0.038, Train loss: 0.410\n",
            "Epoch 89, loss 0.408\n",
            "Epoch 90. Time: 0.034, Train loss: 0.408\n",
            "Epoch 94, loss 0.407\n",
            "Epoch 95. Time: 0.025, Train loss: 0.407\n",
            "Epoch 99, loss 0.406\n",
            "Epoch 100. Time: 0.023, Train loss: 0.405\n",
            "Epoch 104, loss 0.404\n",
            "Epoch 105. Time: 0.025, Train loss: 0.404\n",
            "Epoch 109, loss 0.403\n",
            "Epoch 110. Time: 0.029, Train loss: 0.403\n",
            "Epoch 114, loss 0.402\n",
            "Epoch 115. Time: 0.027, Train loss: 0.402\n",
            "Epoch 119, loss 0.401\n",
            "Epoch 120. Time: 0.030, Train loss: 0.401\n",
            "Epoch 124, loss 0.400\n",
            "Epoch 125. Time: 0.025, Train loss: 0.400\n",
            "Epoch 129, loss 0.399\n",
            "Epoch 130. Time: 0.025, Train loss: 0.399\n",
            "Epoch 134, loss 0.398\n",
            "Epoch 135. Time: 0.027, Train loss: 0.398\n",
            "Epoch 139, loss 0.398\n",
            "Epoch 140. Time: 0.023, Train loss: 0.397\n",
            "Epoch 144, loss 0.397\n",
            "Epoch 145. Time: 0.025, Train loss: 0.397\n",
            "Epoch 149, loss 0.396\n",
            "Epoch 150. Time: 0.025, Train loss: 0.396\n",
            "Epoch 154, loss 0.395\n",
            "Epoch 155. Time: 0.026, Train loss: 0.395\n",
            "Epoch 159, loss 0.394\n",
            "Epoch 160. Time: 0.024, Train loss: 0.394\n",
            "Epoch 164, loss 0.394\n",
            "Epoch 165. Time: 0.028, Train loss: 0.394\n",
            "Epoch 169, loss 0.393\n",
            "Epoch 170. Time: 0.028, Train loss: 0.393\n",
            "Epoch 174, loss 0.392\n",
            "Epoch 175. Time: 0.024, Train loss: 0.392\n",
            "Epoch 179, loss 0.392\n",
            "Epoch 180. Time: 0.024, Train loss: 0.392\n",
            "Epoch 184, loss 0.391\n",
            "Epoch 185. Time: 0.027, Train loss: 0.391\n",
            "Epoch 189, loss 0.391\n",
            "Epoch 190. Time: 0.023, Train loss: 0.390\n",
            "Epoch 194, loss 0.390\n",
            "Epoch 195. Time: 0.024, Train loss: 0.390\n",
            "Epoch 199, loss 0.389"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "arDaa7iZpZYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(15, 128, batch_first=True)"
      ],
      "metadata": {
        "id": "A-c5PgUNoJVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network_lstm(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network_lstm, self).__init__()\n",
        "        self.embed = torch.nn.Embedding(len(CHARS), 15)\n",
        "        self.rnn = torch.nn.LSTM(15, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128,len(CHARS))\n",
        "    def forward(self, sentences, state=None):\n",
        "        embed = self.embed(sentences)\n",
        "        o,s = self.rnn(embed)\n",
        "        out = self.linear(o)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5eX60Gbspann"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network_lstm()"
      ],
      "metadata": {
        "id": "6PN5NPNqpdCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
      ],
      "metadata": {
        "id": "9xGma4VqrAux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(x1,y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_QKWvx7rzKa",
        "outputId": "1a565d0d-0bee-4bf6-b560-2d788ccc7ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.016, Train loss: 2.322\n",
            "\rEpoch 1, loss 2.286\rEpoch 2, loss 2.252\rEpoch 3, loss 2.219\rEpoch 4, loss 2.188\n",
            "Epoch 5. Time: 0.008, Train loss: 2.157\n",
            "\rEpoch 6, loss 2.128\rEpoch 7, loss 2.098\rEpoch 8, loss 2.070\rEpoch 9, loss 2.042\n",
            "Epoch 10. Time: 0.008, Train loss: 2.015\n",
            "\rEpoch 11, loss 1.989\rEpoch 12, loss 1.964\rEpoch 13, loss 1.939\rEpoch 14, loss 1.915\n",
            "Epoch 15. Time: 0.010, Train loss: 1.892\n",
            "\rEpoch 16, loss 1.870\rEpoch 17, loss 1.849\rEpoch 18, loss 1.829\rEpoch 19, loss 1.809\n",
            "Epoch 20. Time: 0.011, Train loss: 1.790\n",
            "Epoch 24, loss 1.720\n",
            "Epoch 25. Time: 0.010, Train loss: 1.703\n",
            "Epoch 29, loss 1.640\n",
            "Epoch 30. Time: 0.009, Train loss: 1.625\n",
            "Epoch 34, loss 1.567\n",
            "Epoch 35. Time: 0.010, Train loss: 1.552\n",
            "Epoch 39, loss 1.497\n",
            "Epoch 40. Time: 0.010, Train loss: 1.483\n",
            "Epoch 44, loss 1.430\n",
            "Epoch 45. Time: 0.009, Train loss: 1.417\n",
            "Epoch 49, loss 1.365\n",
            "Epoch 50. Time: 0.009, Train loss: 1.352\n",
            "Epoch 54, loss 1.300\n",
            "Epoch 55. Time: 0.010, Train loss: 1.288\n",
            "Epoch 59, loss 1.237\n",
            "Epoch 60. Time: 0.012, Train loss: 1.224\n",
            "Epoch 64, loss 1.174\n",
            "Epoch 65. Time: 0.009, Train loss: 1.161\n",
            "Epoch 69, loss 1.111\n",
            "Epoch 70. Time: 0.009, Train loss: 1.098\n",
            "Epoch 74, loss 1.049\n",
            "Epoch 75. Time: 0.011, Train loss: 1.036\n",
            "Epoch 79, loss 0.987\n",
            "Epoch 80. Time: 0.009, Train loss: 0.975\n",
            "Epoch 84, loss 0.928\n",
            "Epoch 85. Time: 0.010, Train loss: 0.916\n",
            "Epoch 89, loss 0.871\n",
            "Epoch 90. Time: 0.010, Train loss: 0.859\n",
            "Epoch 94, loss 0.816\n",
            "Epoch 95. Time: 0.010, Train loss: 0.805\n",
            "Epoch 99, loss 0.764\n",
            "Epoch 100. Time: 0.011, Train loss: 0.754\n",
            "Epoch 104, loss 0.716\n",
            "Epoch 105. Time: 0.009, Train loss: 0.707\n",
            "Epoch 109, loss 0.671\n",
            "Epoch 110. Time: 0.010, Train loss: 0.663\n",
            "Epoch 114, loss 0.630\n",
            "Epoch 115. Time: 0.010, Train loss: 0.622\n",
            "Epoch 119, loss 0.592\n",
            "Epoch 120. Time: 0.010, Train loss: 0.585\n",
            "Epoch 124, loss 0.557\n",
            "Epoch 125. Time: 0.012, Train loss: 0.550\n",
            "Epoch 129, loss 0.525\n",
            "Epoch 130. Time: 0.009, Train loss: 0.519\n",
            "Epoch 134, loss 0.496\n",
            "Epoch 135. Time: 0.009, Train loss: 0.490\n",
            "Epoch 139, loss 0.468\n",
            "Epoch 140. Time: 0.010, Train loss: 0.463\n",
            "Epoch 144, loss 0.443\n",
            "Epoch 145. Time: 0.016, Train loss: 0.438\n",
            "Epoch 149, loss 0.420\n",
            "Epoch 150. Time: 0.008, Train loss: 0.415\n",
            "Epoch 154, loss 0.398\n",
            "Epoch 155. Time: 0.009, Train loss: 0.394\n",
            "Epoch 159, loss 0.378\n",
            "Epoch 160. Time: 0.016, Train loss: 0.374\n",
            "Epoch 164, loss 0.359\n",
            "Epoch 165. Time: 0.012, Train loss: 0.355\n",
            "Epoch 169, loss 0.341\n",
            "Epoch 170. Time: 0.012, Train loss: 0.338\n",
            "Epoch 174, loss 0.324\n",
            "Epoch 175. Time: 0.019, Train loss: 0.321\n",
            "Epoch 179, loss 0.309\n",
            "Epoch 180. Time: 0.012, Train loss: 0.306\n",
            "Epoch 184, loss 0.294\n",
            "Epoch 185. Time: 0.011, Train loss: 0.291\n",
            "Epoch 189, loss 0.280\n",
            "Epoch 190. Time: 0.013, Train loss: 0.278\n",
            "Epoch 194, loss 0.268\n",
            "Epoch 195. Time: 0.012, Train loss: 0.265\n",
            "Epoch 199, loss 0.256"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x2,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-iRGbFcrzKa",
        "outputId": "6eebe1d2-61c1-4fb9-fb55-cf200677d4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.031, Train loss: 4.691\n",
            "\rEpoch 1, loss 3.898\rEpoch 2, loss 3.362\rEpoch 3, loss 2.986\rEpoch 4, loss 2.717\n",
            "Epoch 5. Time: 0.024, Train loss: 2.522\n",
            "Epoch 9, loss 2.146\n",
            "Epoch 10. Time: 0.027, Train loss: 2.097\n",
            "Epoch 14, loss 1.953\n",
            "Epoch 15. Time: 0.025, Train loss: 1.924\n",
            "Epoch 19, loss 1.821\n",
            "Epoch 20. Time: 0.027, Train loss: 1.797\n",
            "Epoch 24, loss 1.707\n",
            "Epoch 25. Time: 0.027, Train loss: 1.685\n",
            "Epoch 29, loss 1.600\n",
            "Epoch 30. Time: 0.024, Train loss: 1.579\n",
            "Epoch 34, loss 1.495\n",
            "Epoch 35. Time: 0.023, Train loss: 1.475\n",
            "Epoch 39, loss 1.393\n",
            "Epoch 40. Time: 0.024, Train loss: 1.372\n",
            "Epoch 44, loss 1.291\n",
            "Epoch 45. Time: 0.032, Train loss: 1.271\n",
            "Epoch 49, loss 1.190\n",
            "Epoch 50. Time: 0.025, Train loss: 1.170\n",
            "Epoch 54, loss 1.091\n",
            "Epoch 55. Time: 0.034, Train loss: 1.071\n",
            "Epoch 59, loss 0.993\n",
            "Epoch 60. Time: 0.027, Train loss: 0.973\n",
            "Epoch 64, loss 0.897\n",
            "Epoch 65. Time: 0.024, Train loss: 0.879\n",
            "Epoch 69, loss 0.806\n",
            "Epoch 70. Time: 0.030, Train loss: 0.789\n",
            "Epoch 74, loss 0.723\n",
            "Epoch 75. Time: 0.025, Train loss: 0.707\n",
            "Epoch 79, loss 0.648\n",
            "Epoch 80. Time: 0.032, Train loss: 0.634\n",
            "Epoch 84, loss 0.584\n",
            "Epoch 85. Time: 0.028, Train loss: 0.572\n",
            "Epoch 89, loss 0.528\n",
            "Epoch 90. Time: 0.027, Train loss: 0.518\n",
            "Epoch 94, loss 0.482\n",
            "Epoch 95. Time: 0.026, Train loss: 0.473\n",
            "Epoch 99, loss 0.442\n",
            "Epoch 100. Time: 0.029, Train loss: 0.435\n",
            "Epoch 104, loss 0.410\n",
            "Epoch 105. Time: 0.031, Train loss: 0.404\n",
            "Epoch 109, loss 0.382\n",
            "Epoch 110. Time: 0.025, Train loss: 0.377\n",
            "Epoch 114, loss 0.359\n",
            "Epoch 115. Time: 0.025, Train loss: 0.355\n",
            "Epoch 119, loss 0.340\n",
            "Epoch 120. Time: 0.029, Train loss: 0.337\n",
            "Epoch 124, loss 0.324\n",
            "Epoch 125. Time: 0.027, Train loss: 0.321\n",
            "Epoch 129, loss 0.311\n",
            "Epoch 130. Time: 0.025, Train loss: 0.309\n",
            "Epoch 134, loss 0.300\n",
            "Epoch 135. Time: 0.029, Train loss: 0.298\n",
            "Epoch 139, loss 0.290\n",
            "Epoch 140. Time: 0.028, Train loss: 0.289\n",
            "Epoch 144, loss 0.283\n",
            "Epoch 145. Time: 0.024, Train loss: 0.281\n",
            "Epoch 149, loss 0.276\n",
            "Epoch 150. Time: 0.024, Train loss: 0.274\n",
            "Epoch 154, loss 0.270\n",
            "Epoch 155. Time: 0.022, Train loss: 0.269\n",
            "Epoch 159, loss 0.265\n",
            "Epoch 160. Time: 0.029, Train loss: 0.264\n",
            "Epoch 164, loss 0.260\n",
            "Epoch 165. Time: 0.027, Train loss: 0.260\n",
            "Epoch 169, loss 0.257\n",
            "Epoch 170. Time: 0.027, Train loss: 0.256\n",
            "Epoch 174, loss 0.253\n",
            "Epoch 175. Time: 0.029, Train loss: 0.253\n",
            "Epoch 179, loss 0.250\n",
            "Epoch 180. Time: 0.026, Train loss: 0.250\n",
            "Epoch 184, loss 0.248\n",
            "Epoch 185. Time: 0.028, Train loss: 0.247\n",
            "Epoch 189, loss 0.245\n",
            "Epoch 190. Time: 0.033, Train loss: 0.245\n",
            "Epoch 194, loss 0.243\n",
            "Epoch 195. Time: 0.026, Train loss: 0.243\n",
            "Epoch 199, loss 0.241"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x3,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l2YBHizrzKa",
        "outputId": "c4df4d0a-a99b-4a6a-8fae-a632c8f4c509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.057, Train loss: 6.007\n",
            "Epoch 4, loss 2.395\n",
            "Epoch 5. Time: 0.053, Train loss: 2.174\n",
            "Epoch 9, loss 1.679\n",
            "Epoch 10. Time: 0.050, Train loss: 1.596\n",
            "Epoch 14, loss 1.333\n",
            "Epoch 15. Time: 0.045, Train loss: 1.278\n",
            "Epoch 19, loss 1.090\n",
            "Epoch 20. Time: 0.053, Train loss: 1.050\n",
            "Epoch 24, loss 0.907\n",
            "Epoch 25. Time: 0.044, Train loss: 0.875\n",
            "Epoch 29, loss 0.765\n",
            "Epoch 30. Time: 0.042, Train loss: 0.741\n",
            "Epoch 34, loss 0.658\n",
            "Epoch 35. Time: 0.053, Train loss: 0.640\n",
            "Epoch 39, loss 0.579\n",
            "Epoch 40. Time: 0.044, Train loss: 0.566\n",
            "Epoch 44, loss 0.522\n",
            "Epoch 45. Time: 0.047, Train loss: 0.513\n",
            "Epoch 49, loss 0.482\n",
            "Epoch 50. Time: 0.047, Train loss: 0.475\n",
            "Epoch 54, loss 0.453\n",
            "Epoch 55. Time: 0.045, Train loss: 0.448\n",
            "Epoch 59, loss 0.432\n",
            "Epoch 60. Time: 0.041, Train loss: 0.428\n",
            "Epoch 64, loss 0.416\n",
            "Epoch 65. Time: 0.039, Train loss: 0.413\n",
            "Epoch 69, loss 0.404\n",
            "Epoch 70. Time: 0.040, Train loss: 0.402\n",
            "Epoch 74, loss 0.395\n",
            "Epoch 75. Time: 0.045, Train loss: 0.393\n",
            "Epoch 79, loss 0.387\n",
            "Epoch 80. Time: 0.040, Train loss: 0.386\n",
            "Epoch 84, loss 0.381\n",
            "Epoch 85. Time: 0.040, Train loss: 0.380\n",
            "Epoch 89, loss 0.376\n",
            "Epoch 90. Time: 0.046, Train loss: 0.375\n",
            "Epoch 94, loss 0.371\n",
            "Epoch 95. Time: 0.044, Train loss: 0.370\n",
            "Epoch 99, loss 0.367\n",
            "Epoch 100. Time: 0.051, Train loss: 0.367\n",
            "Epoch 104, loss 0.364\n",
            "Epoch 105. Time: 0.040, Train loss: 0.364\n",
            "Epoch 109, loss 0.361\n",
            "Epoch 110. Time: 0.043, Train loss: 0.361\n",
            "Epoch 114, loss 0.359\n",
            "Epoch 115. Time: 0.046, Train loss: 0.358\n",
            "Epoch 119, loss 0.357\n",
            "Epoch 120. Time: 0.041, Train loss: 0.356\n",
            "Epoch 124, loss 0.355\n",
            "Epoch 125. Time: 0.041, Train loss: 0.354\n",
            "Epoch 129, loss 0.353\n",
            "Epoch 130. Time: 0.040, Train loss: 0.353\n",
            "Epoch 134, loss 0.351\n",
            "Epoch 135. Time: 0.044, Train loss: 0.351\n",
            "Epoch 139, loss 0.350\n",
            "Epoch 140. Time: 0.042, Train loss: 0.350\n",
            "Epoch 144, loss 0.349\n",
            "Epoch 145. Time: 0.039, Train loss: 0.348\n",
            "Epoch 149, loss 0.348\n",
            "Epoch 150. Time: 0.039, Train loss: 0.347\n",
            "Epoch 154, loss 0.346\n",
            "Epoch 155. Time: 0.048, Train loss: 0.346\n",
            "Epoch 159, loss 0.345\n",
            "Epoch 160. Time: 0.039, Train loss: 0.345\n",
            "Epoch 164, loss 0.344\n",
            "Epoch 165. Time: 0.045, Train loss: 0.344\n",
            "Epoch 169, loss 0.344\n",
            "Epoch 170. Time: 0.055, Train loss: 0.343\n",
            "Epoch 174, loss 0.343\n",
            "Epoch 175. Time: 0.042, Train loss: 0.343\n",
            "Epoch 179, loss 0.342\n",
            "Epoch 180. Time: 0.049, Train loss: 0.342\n",
            "Epoch 184, loss 0.341\n",
            "Epoch 185. Time: 0.043, Train loss: 0.341\n",
            "Epoch 189, loss 0.341\n",
            "Epoch 190. Time: 0.042, Train loss: 0.341\n",
            "Epoch 194, loss 0.340\n",
            "Epoch 195. Time: 0.043, Train loss: 0.340\n",
            "Epoch 199, loss 0.339"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "leoRLaocp9Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru = nn.GRU(15, 128, batch_first=True)"
      ],
      "metadata": {
        "id": "n6qJjEd7oJ8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network_gru(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network_gru, self).__init__()\n",
        "        self.embed = torch.nn.Embedding(len(CHARS), 15)\n",
        "        self.rnn = torch.nn.GRU(15, 128, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(128,len(CHARS))\n",
        "    def forward(self, sentences, state=None):\n",
        "        embed = self.embed(sentences)\n",
        "        o,s = self.rnn(embed)\n",
        "        out = self.linear(o)\n",
        "        return out"
      ],
      "metadata": {
        "id": "MwhJqat_qCWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network_lstm()"
      ],
      "metadata": {
        "id": "wgXhwQ0KqCOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T15:21:01.929404Z",
          "start_time": "2020-03-12T15:21:01.925999Z"
        },
        "id": "aeBhYubTuvsD"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x1,y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHtM6SW2r0OK",
        "outputId": "73f5a517-0cff-4455-93db-84b29d292c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.013, Train loss: 2.324\n",
            "\rEpoch 1, loss 2.295\rEpoch 2, loss 2.266\rEpoch 3, loss 2.239\rEpoch 4, loss 2.212\n",
            "Epoch 5. Time: 0.009, Train loss: 2.187\n",
            "\rEpoch 6, loss 2.162\rEpoch 7, loss 2.137\rEpoch 8, loss 2.113\rEpoch 9, loss 2.090\n",
            "Epoch 10. Time: 0.010, Train loss: 2.067\n",
            "\rEpoch 11, loss 2.044\rEpoch 12, loss 2.021\rEpoch 13, loss 1.998\rEpoch 14, loss 1.976\n",
            "Epoch 15. Time: 0.009, Train loss: 1.953\n",
            "\rEpoch 16, loss 1.931\rEpoch 17, loss 1.909\rEpoch 18, loss 1.887\rEpoch 19, loss 1.865\n",
            "Epoch 20. Time: 0.009, Train loss: 1.843\n",
            "Epoch 24, loss 1.758\n",
            "Epoch 25. Time: 0.008, Train loss: 1.737\n",
            "Epoch 29, loss 1.656\n",
            "Epoch 30. Time: 0.009, Train loss: 1.637\n",
            "Epoch 34, loss 1.562\n",
            "Epoch 35. Time: 0.010, Train loss: 1.544\n",
            "Epoch 39, loss 1.475\n",
            "Epoch 40. Time: 0.009, Train loss: 1.458\n",
            "Epoch 44, loss 1.394\n",
            "Epoch 45. Time: 0.010, Train loss: 1.379\n",
            "Epoch 49, loss 1.320\n",
            "Epoch 50. Time: 0.012, Train loss: 1.305\n",
            "Epoch 54, loss 1.249\n",
            "Epoch 55. Time: 0.009, Train loss: 1.236\n",
            "Epoch 59, loss 1.182\n",
            "Epoch 60. Time: 0.010, Train loss: 1.169\n",
            "Epoch 64, loss 1.118\n",
            "Epoch 65. Time: 0.009, Train loss: 1.106\n",
            "Epoch 69, loss 1.057\n",
            "Epoch 70. Time: 0.010, Train loss: 1.045\n",
            "Epoch 74, loss 0.997\n",
            "Epoch 75. Time: 0.010, Train loss: 0.986\n",
            "Epoch 79, loss 0.941\n",
            "Epoch 80. Time: 0.009, Train loss: 0.930\n",
            "Epoch 84, loss 0.887\n",
            "Epoch 85. Time: 0.011, Train loss: 0.877\n",
            "Epoch 89, loss 0.837\n",
            "Epoch 90. Time: 0.010, Train loss: 0.827\n",
            "Epoch 94, loss 0.790\n",
            "Epoch 95. Time: 0.009, Train loss: 0.780\n",
            "Epoch 99, loss 0.745\n",
            "Epoch 100. Time: 0.009, Train loss: 0.737\n",
            "Epoch 104, loss 0.704\n",
            "Epoch 105. Time: 0.008, Train loss: 0.696\n",
            "Epoch 109, loss 0.666\n",
            "Epoch 110. Time: 0.010, Train loss: 0.658\n",
            "Epoch 114, loss 0.630\n",
            "Epoch 115. Time: 0.009, Train loss: 0.623\n",
            "Epoch 119, loss 0.596\n",
            "Epoch 120. Time: 0.010, Train loss: 0.590\n",
            "Epoch 124, loss 0.564\n",
            "Epoch 125. Time: 0.009, Train loss: 0.558\n",
            "Epoch 129, loss 0.535\n",
            "Epoch 130. Time: 0.011, Train loss: 0.529\n",
            "Epoch 134, loss 0.507\n",
            "Epoch 135. Time: 0.009, Train loss: 0.502\n",
            "Epoch 139, loss 0.481\n",
            "Epoch 140. Time: 0.009, Train loss: 0.476\n",
            "Epoch 144, loss 0.456\n",
            "Epoch 145. Time: 0.015, Train loss: 0.451\n",
            "Epoch 149, loss 0.433\n",
            "Epoch 150. Time: 0.010, Train loss: 0.428\n",
            "Epoch 154, loss 0.411\n",
            "Epoch 155. Time: 0.010, Train loss: 0.407\n",
            "Epoch 159, loss 0.390\n",
            "Epoch 160. Time: 0.010, Train loss: 0.386\n",
            "Epoch 164, loss 0.371\n",
            "Epoch 165. Time: 0.011, Train loss: 0.367\n",
            "Epoch 169, loss 0.353\n",
            "Epoch 170. Time: 0.009, Train loss: 0.349\n",
            "Epoch 174, loss 0.336\n",
            "Epoch 175. Time: 0.016, Train loss: 0.332\n",
            "Epoch 179, loss 0.320\n",
            "Epoch 180. Time: 0.009, Train loss: 0.317\n",
            "Epoch 184, loss 0.305\n",
            "Epoch 185. Time: 0.010, Train loss: 0.302\n",
            "Epoch 189, loss 0.291\n",
            "Epoch 190. Time: 0.009, Train loss: 0.288\n",
            "Epoch 194, loss 0.278\n",
            "Epoch 195. Time: 0.008, Train loss: 0.275\n",
            "Epoch 199, loss 0.266"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x2,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP02qfxur0OK",
        "outputId": "e75ee86a-83cd-4e01-9302-35f8fc93e8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.036, Train loss: 5.035\n",
            "\rEpoch 1, loss 4.283\rEpoch 2, loss 3.757\rEpoch 3, loss 3.357\rEpoch 4, loss 3.048\n",
            "Epoch 5. Time: 0.025, Train loss: 2.807\n",
            "Epoch 9, loss 2.269\n",
            "Epoch 10. Time: 0.024, Train loss: 2.196\n",
            "Epoch 14, loss 1.997\n",
            "Epoch 15. Time: 0.026, Train loss: 1.960\n",
            "Epoch 19, loss 1.836\n",
            "Epoch 20. Time: 0.029, Train loss: 1.809\n",
            "Epoch 24, loss 1.709\n",
            "Epoch 25. Time: 0.028, Train loss: 1.686\n",
            "Epoch 29, loss 1.595\n",
            "Epoch 30. Time: 0.024, Train loss: 1.573\n",
            "Epoch 34, loss 1.487\n",
            "Epoch 35. Time: 0.026, Train loss: 1.465\n",
            "Epoch 39, loss 1.380\n",
            "Epoch 40. Time: 0.024, Train loss: 1.358\n",
            "Epoch 44, loss 1.272\n",
            "Epoch 45. Time: 0.025, Train loss: 1.251\n",
            "Epoch 49, loss 1.165\n",
            "Epoch 50. Time: 0.025, Train loss: 1.143\n",
            "Epoch 54, loss 1.058\n",
            "Epoch 55. Time: 0.034, Train loss: 1.037\n",
            "Epoch 59, loss 0.955\n",
            "Epoch 60. Time: 0.028, Train loss: 0.935\n",
            "Epoch 64, loss 0.857\n",
            "Epoch 65. Time: 0.024, Train loss: 0.839\n",
            "Epoch 69, loss 0.768\n",
            "Epoch 70. Time: 0.023, Train loss: 0.752\n",
            "Epoch 74, loss 0.689\n",
            "Epoch 75. Time: 0.025, Train loss: 0.675\n",
            "Epoch 79, loss 0.621\n",
            "Epoch 80. Time: 0.028, Train loss: 0.609\n",
            "Epoch 84, loss 0.563\n",
            "Epoch 85. Time: 0.024, Train loss: 0.552\n",
            "Epoch 89, loss 0.514\n",
            "Epoch 90. Time: 0.028, Train loss: 0.505\n",
            "Epoch 94, loss 0.472\n",
            "Epoch 95. Time: 0.030, Train loss: 0.465\n",
            "Epoch 99, loss 0.438\n",
            "Epoch 100. Time: 0.037, Train loss: 0.432\n",
            "Epoch 104, loss 0.409\n",
            "Epoch 105. Time: 0.038, Train loss: 0.404\n",
            "Epoch 109, loss 0.385\n",
            "Epoch 110. Time: 0.033, Train loss: 0.380\n",
            "Epoch 114, loss 0.364\n",
            "Epoch 115. Time: 0.033, Train loss: 0.360\n",
            "Epoch 119, loss 0.347\n",
            "Epoch 120. Time: 0.034, Train loss: 0.343\n",
            "Epoch 124, loss 0.332\n",
            "Epoch 125. Time: 0.042, Train loss: 0.329\n",
            "Epoch 129, loss 0.319\n",
            "Epoch 130. Time: 0.033, Train loss: 0.317\n",
            "Epoch 134, loss 0.308\n",
            "Epoch 135. Time: 0.031, Train loss: 0.306\n",
            "Epoch 139, loss 0.298\n",
            "Epoch 140. Time: 0.033, Train loss: 0.297\n",
            "Epoch 144, loss 0.290\n",
            "Epoch 145. Time: 0.035, Train loss: 0.289\n",
            "Epoch 149, loss 0.283\n",
            "Epoch 150. Time: 0.047, Train loss: 0.282\n",
            "Epoch 154, loss 0.277\n",
            "Epoch 155. Time: 0.026, Train loss: 0.276\n",
            "Epoch 159, loss 0.271\n",
            "Epoch 160. Time: 0.027, Train loss: 0.270\n",
            "Epoch 164, loss 0.267\n",
            "Epoch 165. Time: 0.029, Train loss: 0.266\n",
            "Epoch 169, loss 0.262\n",
            "Epoch 170. Time: 0.024, Train loss: 0.261\n",
            "Epoch 174, loss 0.258\n",
            "Epoch 175. Time: 0.025, Train loss: 0.258\n",
            "Epoch 179, loss 0.255\n",
            "Epoch 180. Time: 0.026, Train loss: 0.254\n",
            "Epoch 184, loss 0.252\n",
            "Epoch 185. Time: 0.032, Train loss: 0.251\n",
            "Epoch 189, loss 0.249\n",
            "Epoch 190. Time: 0.024, Train loss: 0.249\n",
            "Epoch 194, loss 0.247\n",
            "Epoch 195. Time: 0.023, Train loss: 0.246\n",
            "Epoch 199, loss 0.245"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(x3,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5TXX70r0OK",
        "outputId": "a8e2f107-cb8b-4e07-ce7f-36454343d514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0. Time: 0.054, Train loss: 5.513\n",
            "\rEpoch 1, loss 4.038\rEpoch 2, loss 3.236\rEpoch 3, loss 2.775\rEpoch 4, loss 2.483\n",
            "Epoch 5. Time: 0.040, Train loss: 2.281\n",
            "Epoch 9, loss 1.829\n",
            "Epoch 10. Time: 0.040, Train loss: 1.751\n",
            "Epoch 14, loss 1.495\n",
            "Epoch 15. Time: 0.050, Train loss: 1.440\n",
            "Epoch 19, loss 1.246\n",
            "Epoch 20. Time: 0.047, Train loss: 1.203\n",
            "Epoch 24, loss 1.046\n",
            "Epoch 25. Time: 0.046, Train loss: 1.011\n",
            "Epoch 29, loss 0.885\n",
            "Epoch 30. Time: 0.041, Train loss: 0.857\n",
            "Epoch 34, loss 0.759\n",
            "Epoch 35. Time: 0.042, Train loss: 0.737\n",
            "Epoch 39, loss 0.663\n",
            "Epoch 40. Time: 0.043, Train loss: 0.646\n",
            "Epoch 44, loss 0.591\n",
            "Epoch 45. Time: 0.056, Train loss: 0.579\n",
            "Epoch 49, loss 0.538\n",
            "Epoch 50. Time: 0.041, Train loss: 0.529\n",
            "Epoch 54, loss 0.498\n",
            "Epoch 55. Time: 0.052, Train loss: 0.492\n",
            "Epoch 59, loss 0.469\n",
            "Epoch 60. Time: 0.045, Train loss: 0.464\n",
            "Epoch 64, loss 0.447\n",
            "Epoch 65. Time: 0.042, Train loss: 0.443\n",
            "Epoch 69, loss 0.430\n",
            "Epoch 70. Time: 0.041, Train loss: 0.427\n",
            "Epoch 74, loss 0.416\n",
            "Epoch 75. Time: 0.041, Train loss: 0.414\n",
            "Epoch 79, loss 0.406\n",
            "Epoch 80. Time: 0.047, Train loss: 0.404\n",
            "Epoch 84, loss 0.397\n",
            "Epoch 85. Time: 0.060, Train loss: 0.396\n",
            "Epoch 89, loss 0.390\n",
            "Epoch 90. Time: 0.053, Train loss: 0.389\n",
            "Epoch 94, loss 0.385\n",
            "Epoch 95. Time: 0.051, Train loss: 0.384\n",
            "Epoch 99, loss 0.380\n",
            "Epoch 100. Time: 0.048, Train loss: 0.379\n",
            "Epoch 104, loss 0.376\n",
            "Epoch 105. Time: 0.045, Train loss: 0.375\n",
            "Epoch 109, loss 0.372\n",
            "Epoch 110. Time: 0.046, Train loss: 0.371\n",
            "Epoch 114, loss 0.369\n",
            "Epoch 115. Time: 0.039, Train loss: 0.368\n",
            "Epoch 119, loss 0.366\n",
            "Epoch 120. Time: 0.040, Train loss: 0.366\n",
            "Epoch 124, loss 0.364\n",
            "Epoch 125. Time: 0.055, Train loss: 0.363\n",
            "Epoch 129, loss 0.361\n",
            "Epoch 130. Time: 0.069, Train loss: 0.361\n",
            "Epoch 134, loss 0.359\n",
            "Epoch 135. Time: 0.061, Train loss: 0.359\n",
            "Epoch 139, loss 0.358\n",
            "Epoch 140. Time: 0.056, Train loss: 0.357\n",
            "Epoch 144, loss 0.356\n",
            "Epoch 145. Time: 0.053, Train loss: 0.356\n",
            "Epoch 149, loss 0.355\n",
            "Epoch 150. Time: 0.066, Train loss: 0.354\n",
            "Epoch 154, loss 0.353\n",
            "Epoch 155. Time: 0.053, Train loss: 0.353\n",
            "Epoch 159, loss 0.352\n",
            "Epoch 160. Time: 0.042, Train loss: 0.352\n",
            "Epoch 164, loss 0.351\n",
            "Epoch 165. Time: 0.041, Train loss: 0.351\n",
            "Epoch 169, loss 0.350\n",
            "Epoch 170. Time: 0.045, Train loss: 0.350\n",
            "Epoch 174, loss 0.349\n",
            "Epoch 175. Time: 0.041, Train loss: 0.349\n",
            "Epoch 179, loss 0.348\n",
            "Epoch 180. Time: 0.044, Train loss: 0.348\n",
            "Epoch 184, loss 0.347\n",
            "Epoch 185. Time: 0.042, Train loss: 0.347\n",
            "Epoch 189, loss 0.346\n",
            "Epoch 190. Time: 0.039, Train loss: 0.346\n",
            "Epoch 194, loss 0.346\n",
            "Epoch 195. Time: 0.039, Train loss: 0.345\n",
            "Epoch 199, loss 0.345"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "P3RX7xNDqCh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x,y):\n",
        " for ep in range(200):\n",
        "    start = time.time()\n",
        "    train_loss = 0.0\n",
        "    train_passed = 0\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        batch = x[i]\n",
        "        batch_out = y[i]\n",
        "        X_batch = batch[:-1]\n",
        "        Y_batch = batch_out[1:].flatten()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(X_batch)\n",
        "        answers = answers.view(-1, len(CHARS))\n",
        "        loss = criterion(answers, Y_batch)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    if ep%5 == 0:\n",
        "      print(\"\\nEpoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss/train_passed))\n",
        "#      s = generate_sentence()\n",
        "#      print(s)\n",
        "    else:\n",
        "      print(f\"\\rEpoch {ep}, loss {train_loss / train_passed:.3f}\", end='')"
      ],
      "metadata": {
        "id": "FarFt_ZM_SgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ИТОГО:**"
      ],
      "metadata": {
        "id": "5cajekle4mL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**значение loss:**"
      ],
      "metadata": {
        "id": "yqUjbpm542k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0UBVcRZy53wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'25':[0.109, 0.247, 0.389], '70':[0.256, 0.241, 0.339], '120':[0.266, 0.245, 0.345]}\n",
        "df = pd.DataFrame(data, index =['RNN', 'LSTM', 'GRU'])"
      ],
      "metadata": {
        "id": "2fLSpEFW5HWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "nzOSWj9P5HSu",
        "outputId": "fb415e7a-15d5-4455-b5a8-7012fecc035a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         25     70    120\n",
              "RNN   0.109  0.256  0.266\n",
              "LSTM  0.247  0.241  0.245\n",
              "GRU   0.389  0.339  0.345"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c904d104-5f6f-4247-9eae-373db7d7f453\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>25</th>\n",
              "      <th>70</th>\n",
              "      <th>120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RNN</th>\n",
              "      <td>0.109</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0.247</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.389</td>\n",
              "      <td>0.339</td>\n",
              "      <td>0.345</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c904d104-5f6f-4247-9eae-373db7d7f453')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c904d104-5f6f-4247-9eae-373db7d7f453 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c904d104-5f6f-4247-9eae-373db7d7f453');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    }
  ]
}